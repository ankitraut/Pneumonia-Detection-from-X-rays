{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport cv2\nimport glob\nimport h5py\nimport shutil\nimport imgaug as aug\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\nimport imgaug.augmenters as augment\nimport tensorflow as tf\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom PIL import Image\nfrom pathlib import Path\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom keras.models import Sequential, Model\nfrom keras.applications.xception import Xception\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D, GlobalAveragePooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping,EarlyStopping,TensorBoard,ReduceLROnPlateau,CSVLogger,LearningRateScheduler\nfrom keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\ncolor = sns.color_palette()\n%matplotlib inline\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bd2a1d89075aa5980bbb594371f03d33115626e7"
      },
      "cell_type": "code",
      "source": "# Implement Learning rate decay\ndef step_decay(epoch):\n    initial_rate = 0.1\n    drop = 0.5\n    epochs_drop = 5.0\n    learning_rate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drops))\n    return learning_rate",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf4a11abdcd44b630518697c4497c1788db66da9"
      },
      "cell_type": "code",
      "source": "train_data = '../input/chest_xray/chest_xray/train/'\nval_data = '../input/chest_xray/chest_xray/val/'\ntest_data = '../input/chest_xray/chest_xray/test/'\n\nnormal_data_dir = '../input/chest_xray/chest_xray/train/NORMAL/'\npneumonia_data_dir = '../input/chest_xray/chest_xray/train/PNEUMONIA/'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "94f30051cc99307377d6b19a13661d22cdf6f3ef"
      },
      "cell_type": "code",
      "source": "aug_gen = ImageDataGenerator(\nrescale = 1./255,\nshear_range = 0.2,\nzoom_range = 0.2,\nhorizontal_flip = True)\n\nval_augs = ImageDataGenerator(rescale =  1./255)\n\ntrain_gen = aug_gen.flow_from_directory(\ntrain_data, \ntarget_size = (224, 224),\nbatch_size = 16,\nshuffle = True,\nclass_mode = 'binary')\n\nval_gen = val_augs.flow_from_directory(\nval_data, \ntarget_size = (224, 224), \nbatch_size = 16,\nshuffle = True,\nclass_mode = 'binary')\n\ntest_gen = val_augs.flow_from_directory(\ntest_data, \ntarget_size = (224, 224), \nbatch_size = 8,\nshuffle = True,\nclass_mode = 'binary')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "28872e6d4e4cdecd749eb3e759b017513833ef36"
      },
      "cell_type": "code",
      "source": "base_model = VGG16(weights = 'imagenet', include_top = False, input_shape = (224,224,3))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\nout = Dense(1, activation='sigmoid')(x)\nclassifier = Model(base_model.input, out)\n\nclassifier.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "87728ecccaf78fc0f42a2a25876eb120e11c9540"
      },
      "cell_type": "code",
      "source": "checkpoint = ModelCheckpoint('./base.model',\n                            monitor = 'val_loss',\n                            verbose = 1,\n                            save_best_only = True,\n                            mode = 'max',\n                            save_weights_only = False,\n                            period = 1)\n\nearlystop = EarlyStopping(monitor = 'val_loss',\n                         min_delta = 0.001,\n                         patience = 30,\n                         verbose = 1,\n                         mode = 'auto')\n\ntensorboard = TensorBoard(log_dir = './logs',\n                         histogram_freq = 0,\n                         batch_size = 16,\n                         write_graph = True,\n                         write_grads = True,\n                         write_images = False)\n\ncsvlogger = CSVLogger(filename = 'training_csv.log',\n                     separator = \",\",\n                     append = False)\n\nlrsched = LearningRateScheduler(step_decay, verbose = 1)\n\nreduce = ReduceLROnPlateau(monitor = 'val_loss',\n                          factor = 0.8,\n                          patience = 5,\n                          verbose = 1,\n                          mode = 'auto',\n                          min_delta = 0.0001,\n                          cooldown = 1,\n                          min_lr = 0.0001)\n\ncallbacks = [checkpoint, tensorboard, earlystop, csvlogger, reduce]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "45cc955f59f11bf866964a9909c5c09a5e76f147"
      },
      "cell_type": "code",
      "source": "classifier.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n\nhistory = classifier.fit_generator(train_gen,\n                                  epochs = 80,\n                                  steps_per_epoch = 30,\n                                  validation_data = test_gen,\n                                  validation_steps = 30,\n                                  callbacks = callbacks,\n                                  verbose = 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f750da3d11fd39b909d5b14909bad4d69b81725e"
      },
      "cell_type": "code",
      "source": "classifier_eval = classifier.evaluate_generator(test_gen)\nprint('classifier: Evaluation: Test Loss', classifier_eval[0])\nprint('classifier: Test Accuracy', classifier_eval[1])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa0c9defe4e0834a739da2d3f8f095359cfeb20c"
      },
      "cell_type": "code",
      "source": "classifier_json = classifier.to_json()\nwith open('classifier.json', 'w') as file:\n    file.write(classifier_json)\n\nclassifier.save('classifier.h5')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}